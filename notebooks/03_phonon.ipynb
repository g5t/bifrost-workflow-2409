{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b699a49c-625d-4d04-8d2b-73acd751b7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipp as sc\n",
    "import plopp as pp\n",
    "import scippneutron as scn\n",
    "import scippnexus as snx\n",
    "import h5py\n",
    "from pathlib import Path\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54d2437-af99-4e39-991c-2eb1311bac38",
   "metadata": {},
   "source": [
    "## An simulated sample with incoherent elastic scattering and one phonon mode\n",
    "The data file specified below contains simulated scattering from a sample with one incoherent elastic scattering mode,\n",
    "and one phonon mode with instrument-parameter controlled slope, `sound_speed`.\n",
    "\n",
    "A standard-McStas particle can only scatter from either the elastic mode _or_ phonon,\n",
    "and this simulation splits the particles equally between the two modes.\n",
    "A better approach would have been sending significantly more particles to the phonon.\n",
    "\n",
    "The phonon FCC lattice constant $a=6.56162$ Å was chosen such that its {200} Bragg peaks (not simulated) \n",
    "would appear at 90 degree $a_4$ in the $E_f = 3.8$ meV analyzers.\n",
    "\n",
    "The simulation was conducted as an sample orientation scan with all other parameters fixed.\n",
    "\n",
    "| Parameter | Value | Notes |\n",
    "|-----------|-------|-------|\n",
    "| `sound_speed` / meV Å | 2.5 |  |\n",
    "| $a_3$ / degree | 0:179 | 1-degree steps, endpoints included |\n",
    "| $a_4$ / degree | 90. | all simulations have this single detector tank position |\n",
    "| pulse-shaping chopper opening time  / msec | 0.2 | picked to be a realistic best-case energy-resolution |\n",
    "| minimum $E_i$ / meV | 2.5 | giving a maximum of ~5.1 meV due to BIFROST's pseudo-white beam |\n",
    "\n",
    "The simulation was started at approxmately 5:37 UTC on 14. September 2024, \n",
    "and required approximately 30 seconds per $a_3$ setting using MPI with 6 nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92e0648-5728-4c28-8924-7bd8563cfc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "datafile = \"20240914/BIFROST_20240914T053723.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2511f25f-46d7-4d36-9cbd-3bf51fa9e364",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bifrost2409.config import POOCH_DATA_DIR, INTERIM_DATA_DIR\n",
    "from bifrost2409.dataset import download_datafiles\n",
    "download_datafiles([datafile])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1012db63-f0c2-49d9-869a-664f8d8c76cf",
   "metadata": {},
   "source": [
    "### Trust the workflow, use the worflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0278f57a-0217-46d7-a032-9d3a915b4b6c",
   "metadata": {},
   "source": [
    "Now that we trust the process that we performed 'by hand' in the last two notebooks,\n",
    "we can make use of the same process available through the workflow in abbreviated form\n",
    "as `bifrost_single`, which _ignores_ any scan information and treats all data as a single setting.\n",
    "\n",
    "> **Note**: Since the workflow is _intended_ for _real_ data, but our simulations need some manipulations\n",
    "> you _must_ specify that this datafile `is_simulated`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555f0f1c-9a06-4629-818b-4ff9e3f03c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ess.spectroscopy.indirect import bifrost_single\n",
    "as_one = bifrost_single(POOCH_DATA_DIR / datafile, is_simulated=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc77d27-0d9d-42a1-aa25-e9dabbab6528",
   "metadata": {},
   "source": [
    "We can get an overview of the per-pixel inelastic spectrum (but we plot it here as a function of 10% of a _tube_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0bb32e6-5b1e-423a-9a6f-72eb64d54ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tube_count = 3 * 9 * 5 * 10\n",
    "as_one['energy_momentum_events'].bin(energy_transfer=100).hist(\n",
    "    energy_transfer=sc.linspace(start=-1.7, stop=1.7, num=50, dim='energy_transfer', unit='meV'),\n",
    "    detector_number=tube_count,\n",
    ").plot(norm='log')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4c178f-faa3-4908-8db4-c40616b340c7",
   "metadata": {},
   "source": [
    "Converting this data to S(**Q**, E) requires splitting the continuous measurement-time dimension of the data into discrete \n",
    "periods with constant settings.\n",
    "> **Note**: currently, this can be done _exactly_ since the `NXlog` values of simulated parameters are stable and precise.\n",
    "> The same should be true in most cases for parameter _set points_, so they will be used to segment real data.\n",
    ">\n",
    "\n",
    "A different workflow entry-point `bifrost` segments the data (currently limited to constant ($a_3$, $a_4$) pairs),\n",
    "then calls, effectively, `bifrost_single` per segment before calculating **Q** _in the sample table coordinate system_ \n",
    "and combining the data.\n",
    "\n",
    "_This process is unoptimized and slow -- about 15 minutes on my laptop, so we will store the result to avoid re-creating it unnecessarily_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fdba3c-2631-4acd-ab80-efcbbf41e351",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ess.spectroscopy.indirect import bifrost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b0f0d7-fca1-4280-b6ac-e9a96d8171f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = ['energy_momentum_events']\n",
    "target_files = {target: INTERIM_DATA_DIR / f'{Path(datafile).stem}_{target}.h5' for target in targets}\n",
    "if all(file.exists() for file in target_files.values()):\n",
    "    from scipp.io import load_hdf5\n",
    "    objects = {target: load_hdf5(file) for target, file in target_files.items()}\n",
    "else:\n",
    "    data = bifrost(POOCH_DATA_DIR / datafile, is_simulated=True)\n",
    "    objects = {target: data[target] for target in targets}\n",
    "    for target in targets:\n",
    "        objects[target].save_hdf5(target_files[target])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1d7921-1934-4088-9057-1fbf8827cec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_momentum_events = objects['energy_momentum_events']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411d8275-33a5-4e11-8107-ee0fde1a04c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hist_Q_plane(events, energy_transfer_range, q_bins):\n",
    "    a = events.bin(energy_transfer=energy_transfer_range)\n",
    "    # Remove coordinates and event coordinates that we're not using:\n",
    "    for coord in ('a3', 'a4', 'detector_number', 'final_energy'):\n",
    "        del a.coords[coord]\n",
    "    for coord in ('event_time_offset', 'event_time_zero', 'frame_time', 'incident_energy', 'lab_momentum_x', 'lab_momentum_z'):\n",
    "        del a.bins.coords[coord]\n",
    "    # drop the non-energy_transfer dimensions before binning in Q\n",
    "    for dim in ('setting', 'event_id'):\n",
    "        a = a.bins.concat(dim)\n",
    "    return a.bin(table_momentum_x=q_bins, table_momentum_z=q_bins).hist()['energy_transfer', 0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a25171-dbff-45a2-a83a-cfe8def18ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_Q_plane(energy_momentum_events, sc.array(values=[-0.05, 0.05], dims=['energy_transfer'], unit='meV'), 200).plot(norm='log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86899159-ecb0-486f-b6e8-cd51846ff90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_Q_plane(energy_momentum_events, sc.array(values=[0.3, 0.9], dims=['energy_transfer'], unit='meV'), 200).plot(norm='log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c7e2b2-f905-4b71-a263-7778840cba85",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_Q_plane(energy_momentum_events, sc.array(values=[1., 1.6], dims=['energy_transfer'], unit='meV'), 200).plot(norm='log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf50ed26-0628-49fd-8e65-6b0483062c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hist_E_plane(events, q_x_range, q_bins, e_bins):\n",
    "    a = events.bin(table_momentum_x=q_x_range)\n",
    "    # Remove coordinates and event coordinates that we're not using:\n",
    "    for coord in ('a3', 'a4', 'detector_number', 'final_energy'):\n",
    "        del a.coords[coord]\n",
    "    for coord in ('event_time_offset', 'event_time_zero', 'frame_time', 'incident_energy', 'lab_momentum_x', 'lab_momentum_z'):\n",
    "        del a.bins.coords[coord]\n",
    "    # drop the non-energy_transfer dimensions before binning in Q\n",
    "    for dim in ('setting', 'event_id'):\n",
    "        a = a.bins.concat(dim)\n",
    "    return a.bin(energy_transfer=e_bins, table_momentum_z=q_bins).hist()['table_momentum_x', 0]\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175247e5-2c8c-4d68-ba81-21c9b7f1feed",
   "metadata": {},
   "outputs": [],
   "source": [
    "astar = 2 * np.pi / 6.56162"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfea0389-313b-4874-9374-54e7b145c278",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_E_plane(energy_momentum_events, sc.array(values=[2 * astar - 0.2,  2 * astar + 0.2], dims=['table_momentum_x'], unit='1/angstrom'), 200, 50).plot(norm='log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfb09f3-6ab1-43d8-a1f0-70fe8501a117",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
